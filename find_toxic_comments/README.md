# Выявление токсичных комментариев
Статус: Проект завершен.

## Описание проекта
Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 
В рамках данного проекта была разработана модель МО для классификации комментариев на позитивные и негативные на основе набора данных с разметкой о токсичности правок.

## Использованные инструменты и библиотеки
Python, pandas, sklearn, matplotlib, phik, Pipeline, LogisticRegression, RandomForestClassifier, SGDClassifier.

## Вывод
В ходе данного проекта были изучены данные интернет-магазина, относящиеся к работе нового сервиса, в котором пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Задачей проекта была разработка модели машинного обучения для поиска токсичных комментариев, которые необходимо отправлять на модерацию.

В ходе **этапа обзора и первичной обработки данных** было выяснено, что:
- присутствует дисбаланс классов в целевом признаке: позитивных отзывов (класс "0") в 8.8 раз больше, чем токсичных (класс "1").
- После приведения данных в столбце `text` к нижнему регистру обнаружено 45 дублирующихся строчек, которые были удалены.

На этапе **подготовки текста**:

- провели предобработку текста: очистили от неинформативных символов, токенизировали и лемматизировали.
- разделили данные на обучающую и тестовую выборку в соотношении train/test 3:1 с учетом стратификации по целевому признаку.
- создали корпусы текстов для обучающей и тестовой выборки,
- очистили их от стоп-слов,
- создали матрицу cо значениями TF-IDF по корпусу текстов.

На этапе **обучения** были обучены 3 модели: LogisticRegression, RandomForestClassifier и SGDClassifier. В качестве метрики качества использовалась F1-мера, т.к. в данной задаче важны ошибки и 1го и 2го родов.

На этапе **тестирования** модель логистической регрессии показала наилучшую метрику f1 на кросс-валидации равную 0.76. Модели LogisticRegression и SGDClassifier проходят по критерию значение метрики качества F1 не меньше 0.75. Т.к. в продакшн можно взять только одну модель, выберем логистическую регрессию, показавшую чуть лучшую метрику.

Параметры лучшей модели: LogisticRegression(C=13, max_iter=200, random_state=42, solver='liblinear').

F1 метрика на тестовых данных оказалась близка метрике на кросс-валидации и равна 0.77.

По матрице ошибок выяснилось, что модель чаще совершает ошибки первого рода, т.е. классифицирует токсичные комментарии как положительные (492 случаев). И в 3 раза меньше ошибок 2го рода, т.е. классифицирует положительные комментарии как токсичные. Вероятно, это связано с дисбалансом классов. Т.к. положительных комментариев (класс "0") больше, то модель чаще ее присваивает, в том числе и ошибочно. Таким образом, зоной роста является работа над уменьшением влияния дисбаланса классов.
